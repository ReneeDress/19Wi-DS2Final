This CSS module specifies the contain property, which can be used to indicate elements whose subtree is independent of the rest of the page in some manner. ======CSS Containment Now a Web Standard
That independence may then be used by user agents to provide much stronger optimizations when rendering a page, while allowing authors to be confident that their page won’t accidentally fall into a slow code path due to an innocuous change. ======CSS Containment Now a Web Standard
The main goal of CSS Containment standard is to improve the rendering performance of web pages by skipping some document subtrees in parts of the page rendering process. ======CSS Containment Now a Web Standard
Rachel Andrew, editor in chief of Smashing Magazine, explains in an article dedicated to the new web standard. ======CSS Containment Now a Web Standard
When the content of our box is changed, the browser has to consider that any of the elements may have changed. ======CSS Containment Now a Web Standard
That said, as the developer, you will know if each of the components is independent, and that a change to one doesn’t affect the others, so it would be nice if you could let the browser know this via your CSS. ======CSS Containment Now a Web Standard
The module specification specifies a contain property to allow predictable isolation of a subtree from the rest of the page. ======CSS Containment Now a Web Standard
The contain property indicates that an element and its contents are independent of the rest of the document tree in some manner that is specified by picking one of five values: strict, content, size, layout, paint. ======CSS Containment Now a Web Standard
The layout value of the contain property indicates that the internal layout of the element is not affected by anything outside the element and the element’s contents cannot have any effect on the ancestors. ======CSS Containment Now a Web Standard
The paint value indicates that descendants of the element cannot be displayed outside its bounds and that nothing will overflow this element (or if it does it won’t be visible). ======CSS Containment Now a Web Standard
The content value is a shortcut for contain: layout paint, while the strict value is a shortcut for layout paint size. ======CSS Containment Now a Web Standard
The contain property allows the browser to recalculate layout, style, paint, size, or any combination of them for a limited area of the DOM and not the entire page, leading to obvious reflow and repaint performance benefits, especially in large pages. ======CSS Containment Now a Web Standard
The performance gains are large enough for Bloomberg to support Igalia’s work on the CSS Containment implementation in Chromium. ======CSS Containment Now a Web Standard
Manuel Rego Casasnovas provided in his talk at CSSconf EU 2019 an example of UI with over 10,000 cells whose text content is changing constantly, and which could be rendered 4x faster. ======CSS Containment Now a Web Standard
Bloomberg has some quite complex UIs and [they are] getting benefits of using CSS containment on some of them. ======CSS Containment Now a Web Standard
Paul Lewis described to performance-minded developers which parts of the rendering process are affected by changes in DOM property. ======CSS Containment Now a Web Standard
The site csstriggers additionally gathers the properties that trigger a layout, according to the browser used. ======CSS Containment Now a Web Standard
Melanie Richards discussed the client-side video editing proposal that the Edge team at Microsoft has been working on. ======New Proposal Improves Client-Side Video Editing by Four Times
The proposal is in the incubation phase at the Web Platform Incubator Community Group(WICG) and aims at enabling dramatically faster client-side video editing experience and better performance. ======New Proposal Improves Client-Side Video Editing by Four Times
We heard from the media partners that providing a low-latency media experience on the web can be challenging. ======New Proposal Improves Client-Side Video Editing by Four Times
[…] To address this, we prototyped a MediaBlog API which enables client-side media editing, such as trimming and concatenation. ======New Proposal Improves Client-Side Video Editing by Four Times
The client-side video editing proposal is incubated at the WICG and is developed by incorporating the feedback of companies that have a need for this technology. ======New Proposal Improves Client-Side Video Editing by Four Times
Early experiments have been conducted with the social-learning company FlipGrid which is listed as having Microsoft Corporation as a parent company, and shows dramatic improvements in processing speed. ======New Proposal Improves Client-Side Video Editing by Four Times
[Early prototypes] used at the social-learning site FlipGrid indicates that video editing with the proposed client-side API can be 4x faster than the standard approach, going from a three-second processing to 768-millisecond. ======New Proposal Improves Client-Side Video Editing by Four Times
The proposal introduces a MediaBlob interface that extends the regular Blob (Binary Large OBject) interface and a MediaBlobOperation interface that is used to batch the proposed media editing operations. ======New Proposal Improves Client-Side Video Editing by Four Times
The MediaBlobOperation interface includes, as of the publication date of this news piece, methods for three operations: trimming, splitting, and concatenating videos. ======New Proposal Improves Client-Side Video Editing by Four Times
When executed on a MediaBlob, it will return a MediaBlob that keeps the content of the original MediaBlob that belongs to the parameterized time interval, and discards the rest. ======New Proposal Improves Client-Side Video Editing by Four Times
The split method allows the author to split a Blob into two separate MediaBlobs at a given time that is passed as parameter. ======New Proposal Improves Client-Side Video Editing by Four Times
The three operations are batched by default, and invoking the methods does not lead to the execution of the operations. ======New Proposal Improves Client-Side Video Editing by Four Times
The previous sample code illustrates a program that converts a Blob into a MediaBlob, and constructs from that a MediaBlobOperation. ======New Proposal Improves Client-Side Video Editing by Four Times
When running the finalize method, the client-side runtime will extract the content between 4 seconds and 6 minutes (360 seconds) after the beginning of the Blob, concatenate a second Blob to that, and run a callback function on the result. ======New Proposal Improves Client-Side Video Editing by Four Times
The Blob interface was introduced in the File API proposal (hosted by the W3C) and represents immutable raw binary data, and allows access to ranges of bytes within the Blob object as a separate Blob. ======New Proposal Improves Client-Side Video Editing by Four Times
The Web Platform Incubator Community Group (WICG) provides a lightweight venue for proposing and discussing new web platform features. ======New Proposal Improves Client-Side Video Editing by Four Times
W3C is an international community that develops open standards to ensure the long-term growth of the Web. ======New Proposal Improves Client-Side Video Editing by Four Times
Eric Estabrooks from DataKitchen spoke at this year's Data Architecture Summit 2019 Conference about how DevOps tasks should be managed for data architecture. ======DataOps and Operations-Centric Data Architecture
"DataOps" is a collaborative data management practice, and is emerging as an area of interest in the industry. ======DataOps and Operations-Centric Data Architecture
Similar to how DevOps resulted in a transformative improvement in software development, and how Lean has resulted in improvements in manufacturing, DataOps aims to create an agile data culture in organizations. ======DataOps and Operations-Centric Data Architecture
Currently, data teams at most organizations have high errors in data management operations every month, due to factors like incorrect data, broken reports, late delivery, and customer complaints. ======DataOps and Operations-Centric Data Architecture
Most companies are also slow in creating new development environments as well as deploying data analytic pipeline changes to production. ======DataOps and Operations-Centric Data Architecture
Estabrooks mentioned that hero mentality that we see in some teams is actually career-ending, and is bad for individual team members and also for the team as a whole. ======DataOps and Operations-Centric Data Architecture
Instead, he recommends teams to create repeatable processes for quality and predictable database builds and deployments. ======DataOps and Operations-Centric Data Architecture
A DataOps mindset change is needed in order to power agile data culture; this includes transition from manual operations to automated operations, a tool-centric approach to a code-centric one, as well as integrating quality into product features from earlier phases in the data management lifecycle. ======DataOps and Operations-Centric Data Architecture
Estabrooks discussed a seven-step process for diverse teams in organizations (data analysts, data scientists, and data engineers) to realize the DataOps transformation and deliver business value quickly and with high quality. ======DataOps and Operations-Centric Data Architecture
He also explained the DataOps centric architecture model and how it's different from traditional canonical data architecture. ======DataOps and Operations-Centric Data Architecture
In canonical data architecture we only think about production, not the process, when making changes to production. ======DataOps and Operations-Centric Data Architecture
" Teams think first about changes over time to their code, servers, tools, and monitoring for errors, as first class citizens in the design. ======DataOps and Operations-Centric Data Architecture
He described the functional and physical perspectives of DataOps architecture, which include a DataOps platform consisting of separate components for storage, metadata, authentication, secrets management, and metrics. ======DataOps and Operations-Centric Data Architecture
Estabrooks concluded the presentation by listing the goals of DataOps architecture, which include updating and publishing changes to analytics within a short time without disrupting operations, discovery of data errors before they reach published analytics, and creating and publishing schema changes as frequently as every day. ======DataOps and Operations-Centric Data Architecture
0 release of the cross-browser testing framework now supports automation with all evergreen browsers based on the Chromium, Firefox, and WebKit browser engines. ======Playwright 1.0 Release Automates Chromium, Firefox, and WebKit-Based Browsers
Major alternatives to Playwright include Puppeteer, which only supports Chromium-based browsers, and WebDriver, which many consider being somewhat flaky and challenging by comparison. ======Playwright 1.0 Release Automates Chromium, Firefox, and WebKit-Based Browsers
Below is the simplest example of using Playwright to browse to a website in three major browsers, where it saves a screenshot for each. ======Playwright 1.0 Release Automates Chromium, Firefox, and WebKit-Based Browsers
Through Playwright's asynchronous and event-driven architecture, Playwright automatically waits for the UI to be ready rather than a brittle dependency on timeout mechanisms. ======Playwright 1.0 Release Automates Chromium, Firefox, and WebKit-Based Browsers
To keep testing fast and efficient, within a single browser context, Playwright can work with multiple web views and contextual behavior to parallelize testing. ======Playwright 1.0 Release Automates Chromium, Firefox, and WebKit-Based Browsers
Other key features include emulating mobile environments, geolocation, and locales to test real user experiences. ======Playwright 1.0 Release Automates Chromium, Firefox, and WebKit-Based Browsers
Other significant features of Playwright include the ability to automate and test web components, network activity, file uploads and downloads, cross-frame and cross-tab activities, native inputs, web workers, and more. ======Playwright 1.0 Release Automates Chromium, Firefox, and WebKit-Based Browsers
Playwright currently requires custom patched builds of WebKit and Firefox which get download automatically when installing Playwright. ======Playwright 1.0 Release Automates Chromium, Firefox, and WebKit-Based Browsers
Collaboration is underway with the Firefox and WebKit teams to include these patches in future versions of Firefox and WebKit. ======Playwright 1.0 Release Automates Chromium, Firefox, and WebKit-Based Browsers
There is also a Try Playwright playground to get started with Playwright and examples for usage with some test runners. ======Playwright 1.0 Release Automates Chromium, Firefox, and WebKit-Based Browsers
Contributions are welcome via the Playwright contribution guidelines, following the Microsoft open source code of conduct. ======Playwright 1.0 Release Automates Chromium, Firefox, and WebKit-Based Browsers
As companies start to add Big Data and Machine Learning initiatives to their project portfolios, they face several challenges including the teams' transition from software engineering to data engineering and machine learning. ======A Team's Transformation from Software Development to ML: Golestan Radwan at QCon NY
Golestan "Sally" Radwan recently spoke at QCon New York 2018 Conference about her experience in leading a traditional software engineering team on a machine learning/AI journey. ======A Team's Transformation from Software Development to ML: Golestan Radwan at QCon NY
Techniques like frequent and visual communication helped them but they had to make some tough technology and people decisions. ======A Team's Transformation from Software Development to ML: Golestan Radwan at QCon NY
Individual transformation included moving from languages like PHP and Python; changing the technology was not easy. ======A Team's Transformation from Software Development to ML: Golestan Radwan at QCon NY
The developers had to get comfortable with handling completely different data structures, formats, and data sources. ======A Team's Transformation from Software Development to ML: Golestan Radwan at QCon NY
At the team level, they focused on regular knowledge sharing sessions; "lunch and learn" meetings were held every Thursday, in which team members could share what they learned. ======A Team's Transformation from Software Development to ML: Golestan Radwan at QCon NY
They also codifed this knowledge and automated associated processes using CircleCI in order to make the most use of Data Scientists valuable time. ======A Team's Transformation from Software Development to ML: Golestan Radwan at QCon NY
Speaking of Data Science discipline, Radwan suggested to look for some development skills (at least to prototype) when hiring data scientists. ======A Team's Transformation from Software Development to ML: Golestan Radwan at QCon NY
Probe their real world understanding to learn how much they care about the big picture, company goals, and how they fit in the organization. ======A Team's Transformation from Software Development to ML: Golestan Radwan at QCon NY
And finally at the organization level, if you have a podium, speak up and set expectations to your stakeholders. ======A Team's Transformation from Software Development to ML: Golestan Radwan at QCon NY
She concluded the discussion by suggesting the teams resist the urge to overcomplicate things so they can be successful in their machine learning initiatives. ======A Team's Transformation from Software Development to ML: Golestan Radwan at QCon NY
Recently launched in preview by Microsoft, ION is a Decentralized Identifier (DID) network that runs on top of Bitcoin and aims to provide a decentralized identity system and PKI at scale. ======Microsoft Launches Blockchain-Based Decentralized Identity System
Today, the most common digital identifiers we use are email addresses and usernames, provided to us by apps, services, and organizations. ======Microsoft Launches Blockchain-Based Decentralized Identity System
This puts identity providers in a place of control, between us and every digital interaction in our lives. ======Microsoft Launches Blockchain-Based Decentralized Identity System
Decentralized identities promise to change this picture by enabling an ecosystem where large numbers of organizations and individuals can operate securely, while fully preserving their privacy, without any company, organization or group deciding who may participate by controlling identifiers and PKI entries. ======Microsoft Launches Blockchain-Based Decentralized Identity System
ION, short for Identity Overlay Network, is based on the Sidetree protocol, which is backed by the Digital Identity Foundation, a consortium of more than 60 members, including Microsoft, IBM, NEC and others. ======Microsoft Launches Blockchain-Based Decentralized Identity System
The main appeal of ION is its capacity of achieving tens-of-thousands of operations per second, thus overcoming a fundamental limitation of other decentralized identity systems and other systems based on blockchain transactions. ======Microsoft Launches Blockchain-Based Decentralized Identity System
This made it possible to define the Sidetree protocol in such a way that it can operate at scale without requiring a Layer 2 consensus scheme, trusted validator lists, or other solutions aiming to improve blockchain transaction performance. ======Microsoft Launches Blockchain-Based Decentralized Identity System
All nodes of the network are able to arrive at the same Decentralized Public Key Infrastructure (DPKI) state for an identifier based solely on applying deterministic protocol rules to chronologically ordered batches of operations anchored on the blockchain, which ION nodes replicate and store via IPFS. ======Microsoft Launches Blockchain-Based Decentralized Identity System
ION is just a step towards Microsoft's vision for decentralized identity, which rests on a few tenets including user-owned identifiers, secure and user-controlled, "off-the-chain" datastores for actual identity data, and more. ======Microsoft Launches Blockchain-Based Decentralized Identity System
Work on ION is not complete, since ION is being released as a preview and is still best suited for use by experienced developers only, says Microsoft. ======Microsoft Launches Blockchain-Based Decentralized Identity System
In the coming months, though, ION codebase is expected to evolve rapidly and mature to the point it can be released publicly on Bitcoin mainnet. ======Microsoft Launches Blockchain-Based Decentralized Identity System
During Microsoft's annual Ignite conference the company announced a new analytics service called Azure Synapse. ======Microsoft Announces Azure Synapse for Data Warehousing and Analytics
The service, which is a continuation of Azure SQL Data Warehouse, focuses on bringing enterprise data warehousing and big data analytics into a single service. ======Microsoft Announces Azure Synapse for Data Warehousing and Analytics
With Azure Synapse, Microsoft aims to bring together both data warehouses and data lakes in order to provide a single service for collaboration, building, managing, and analyzing the information. ======Microsoft Announces Azure Synapse for Data Warehousing and Analytics
All of these different roles work with the same tooling, named Azure Synapse studio, which has a different look and feel for each of the different personas working with the data, ranging from visual pipelines to queries using the familiar SQL syntax. ======Microsoft Announces Azure Synapse for Data Warehousing and Analytics
What's more, Microsoft indicates that it is possible to run TPC-H queries at petabyte-scale or similar, although they do provide best practices to ensure reaching this type of performance. ======Microsoft Announces Azure Synapse for Data Warehousing and Analytics
Azure Synapse consists of four components in total, each focused on a different part of processing the various workloads. ======Microsoft Announces Azure Synapse for Data Warehousing and Analytics
SQL Analytics implement T-SQL based analytics, and comes with the capabilities that were previously in Azure SQL Data Warehouse. ======Microsoft Announces Azure Synapse for Data Warehousing and Analytics
Even though some of these components are still in preview, the service itself is now generally available. ======Microsoft Announces Azure Synapse for Data Warehousing and Analytics
As is often the case in Azure, there is tight integration with other Azure services, including the various data platforms and tooling such as Power BI and Azure Machine Learning. ======Microsoft Announces Azure Synapse for Data Warehousing and Analytics
However, Azure Synapse not only integrates with its ecosystem, but also with partners like Databricks, Informatica, Accenture, Talend, Panoply, Attunity, Pragmatic Works, and Adatis. ======Microsoft Announces Azure Synapse for Data Warehousing and Analytics
Consequently the service is similar to data warehouses from other cloud providers, such as AWS Redshift and Google Cloud's BigQuery. ======Microsoft Announces Azure Synapse for Data Warehousing and Analytics
For example, there are several built-in options for implementing security around connectivity like firewall integration, as well as encryption both in transit and at rest. ======Microsoft Announces Azure Synapse for Data Warehousing and Analytics
There is also the option to implement authentication using Azure Active Directory alongside using username/password logins, and various roles define the privileges available for users. ======Microsoft Announces Azure Synapse for Data Warehousing and Analytics
There are also a variety of automated security measures possible, including the option to automatically classify data through discovery and classification, while Advanced Threat Protection provides alerts whenever any suspicious behavior occurs. ======Microsoft Announces Azure Synapse for Data Warehousing and Analytics
Pascal Desmarets, CEO of Hackolade, recently spoke at Data Architecture Summit 2018 Conference about agile modeling for NoSQL databases. ======Agile Data Modeling for NoSQL Databases
He said that data modeling is even more important in NoSQL databases when the constraints provided by normalization have been taken down. ======Agile Data Modeling for NoSQL Databases
Unstructured and polymorphic big data creates challenges both in terms of data governance and regulations (GDPR and PII) and the ability to leverage the information accumulated. ======Agile Data Modeling for NoSQL Databases
Benefits of data modeling in relational and NoSQL databases include higher application quality, improved data quality, GDPR & privacy identifiable information and business intelligence. ======Agile Data Modeling for NoSQL Databases
For example, choose key-value store if you need to manage simple schema and faster read/write with no frequent updates. ======Agile Data Modeling for NoSQL Databases
And graph databases are better for applications requiring traversal between data points where you need the ability to store properties of each data point as well as relationships between them. ======Agile Data Modeling for NoSQL Databases
He talked about traditional data modeling process and how we are transitioning from data modeling to schema design approach. ======Agile Data Modeling for NoSQL Databases
Conceptual data model has been replaced by domain-driven design (DDD), logical data model is no longer needed, and physical data model is replaced by physical schema design. ======Agile Data Modeling for NoSQL Databases
In the Agile development process, data modeling has a role in every step of the process, including in production. ======Agile Data Modeling for NoSQL Databases
Data modeling effort becomes a shared responsibility and a dialog between multiple project stakeholders. ======Agile Data Modeling for NoSQL Databases
He also said that domain-driven design (DDD) and NoSQL are made for each other and there is a direct match between DDD language and the concepts of NoSQL databases. ======Agile Data Modeling for NoSQL Databases
He advocates that coherence is necessary throughout strategy, process, architecture, and technology, as it is preferable to apply all these principles together rather than just one or two in isolation: Domain-Driven Design, Agile development, Data-Centricity, Microservices, Event-Driven architecture, NoSQL, DevOps, and Cloud. ======Agile Data Modeling for NoSQL Databases
InfoQ spoke with Desmarets about the best practices of data modeling of NoSQL databases and big data management. ======Agile Data Modeling for NoSQL Databases
Pascal Desmarets:   The global method is very similar, but the implementation can be vastly different. ======Agile Data Modeling for NoSQL Databases
To leverage the benefits of NoSQL, it is critical to design data models that are application-specific, so you store information in a way that optimizes query performance. ======Agile Data Modeling for NoSQL Databases
This mind shift can be a challenge for those who have been applying the principles of application-agnostic data modeling for decades. ======Agile Data Modeling for NoSQL Databases
For many of us, the rules of normalization have become second nature, and we have to force ourselves to apply a query-driven approach to schema design for NoSQL databases. ======Agile Data Modeling for NoSQL Databases
But when it comes to the specific aspects of schema design for each technology, the biggest difference is between graph databases and the three other families of NoSQL DBs. ======Agile Data Modeling for NoSQL Databases
The nature of graph databases is such that graph traversal performance -- when executing queries -- requires that an attribute in any other technology, may be promoted to the status of an entity (or node) in the case of a graph database. ======Agile Data Modeling for NoSQL Databases
For graph databases for examples, there’s a fundamental difference between property graph DBs and RDF triple stores. ======Agile Data Modeling for NoSQL Databases
Within JSON document databases, you will find structural storage differences between Couchbase for example, and MongoDB. ======Agile Data Modeling for NoSQL Databases
Desmartes:  Data modeling as we’ve known it for decades is under a lot of pressure in the context of Agile development. ======Agile Data Modeling for NoSQL Databases
Despite attempts to make data modeling more agile, it is often viewed as a bottleneck to the speed and cadence of two-week sprints. ======Agile Data Modeling for NoSQL Databases
The truth is that some form of schema design is indispensable, meaning that data modeling needs to be re-invented to remain relevant. ======Agile Data Modeling for NoSQL Databases
First, data modeling needs to be an iterative process through the development sprints and through the application lifecycle, instead of being a heavy front-loaded task. ======Agile Data Modeling for NoSQL Databases
Data modeling also needs to be a collaborative process between data modelers (who are outstanding at abstracting their understanding of the business) and developers (who really understand how to translate requirements into code). ======Agile Data Modeling for NoSQL Databases
The methodology needs to be adapted to the development techniques and the technology stack, in particular with a query-driven and application-specific approach as described earlier. ======Agile Data Modeling for NoSQL Databases
It must combine Domain-Driven Design, user experience and flowcharting of business rules, combined with screen wireframes and reports, to derive the application queries to take into account when designing the schemas. ======Agile Data Modeling for NoSQL Databases
He also said that for quite some time, NoSQL database vendors have created a differentiation and a buzz by using terms like ‘schema-less’ or ‘non-relational’. ======Agile Data Modeling for NoSQL Databases
But NoSQL databases are so flexible and powerful that inexperienced users can easily get in trouble if they don’t apply some rigorous techniques. ======Agile Data Modeling for NoSQL Databases
And the vendors now realize that, in order to sell their solutions to enterprises, it is wiser to use the term ‘dynamic schema’ instead. ======Agile Data Modeling for NoSQL Databases
Data modeling (or schema design) is in fact more important when dealing with NoSQL than it was with relational databases. ======Agile Data Modeling for NoSQL Databases
And data modelers should embrace Agile development and learn the implications of new technology stacks to prove their added-value in the process. ======Agile Data Modeling for NoSQL Databases
Introduced at the AWS re:Invent 2018 event, Amazon Managed Blockchain has left preview and reached general availability. ======Fully Managed Blockchain Networks with Amazon Managed Blockchain Now Generally Available
This new service aims to simplify creating and managing scalable blockchain networks based on Hyperledger Fabric and, soon, Ethereum. ======Fully Managed Blockchain Networks with Amazon Managed Blockchain Now Generally Available
Amazon Managed Blockchain enables a group of members to execute transactions and share data without the need of a central authority or central server to grant transaction trustworthiness. ======Fully Managed Blockchain Networks with Amazon Managed Blockchain Now Generally Available
Running a blockchain network usually requires each member of the network to provide hardware, install software, and to deal with cryptographic certificates for access control. ======Fully Managed Blockchain Networks with Amazon Managed Blockchain Now Generally Available
This complexity is where Amazon is trying to provide value to developers with Amazon Managed Blockchain, which can provision network nodes, manage certificates, and take care of scaling the network when required. ======Fully Managed Blockchain Networks with Amazon Managed Blockchain Now Generally Available
According to Amazon, developers can set up a managed blockchain network in just few clicks, which will allow them to focus on their own blockchain applications and not on the underlying infrastructure. ======Fully Managed Blockchain Networks with Amazon Managed Blockchain Now Generally Available
Currently, developers can use Hyperledger Fabric, a blockchain framework that Amazon says is well-suited for applications requiring stringent privacy and permission controls with a known set of members. ======Fully Managed Blockchain Networks with Amazon Managed Blockchain Now Generally Available
Amazon plans to offer soon the possibility of using Ethereum, which is geared to highly distributed networks. ======Fully Managed Blockchain Networks with Amazon Managed Blockchain Now Generally Available
Once your network has been created, you can invite other AWS members to join the network, then add peer nodes and deploy your applications. ======Fully Managed Blockchain Networks with Amazon Managed Blockchain Now Generally Available
Each member should have at least one node, which will keep a copy of the shared ledger and will interact with other peers to perform new transactions. ======Fully Managed Blockchain Networks with Amazon Managed Blockchain Now Generally Available
2, which provides the APIs for application developers to implement Smart Contracts, also known as chaincodes in Hyperledger Fabric jargon. ======Fully Managed Blockchain Networks with Amazon Managed Blockchain Now Generally Available
Network members can add capacity to their network, for example to create or validate transactions, using Managed Blockchain's API. ======Fully Managed Blockchain Networks with Amazon Managed Blockchain Now Generally Available
To improve Hyperledger Fabric reliability, Amazon has replaced Apache Kafka, which can be used to ensure sequential delivery of all transactions, with Amazon Quantum Ledger Database (QLDB). ======Fully Managed Blockchain Networks with Amazon Managed Blockchain Now Generally Available
Amazon QLDB is a fully managed ledger database used to store transactions granting transparency, immutability, and verifiability under a central trusted authority. ======Fully Managed Blockchain Networks with Amazon Managed Blockchain Now Generally Available
A blockchain is a decentralized, distributed digital ledger able to record transactions across many computers. ======Fully Managed Blockchain Networks with Amazon Managed Blockchain Now Generally Available
In a recent press release, Hyperledger, an open-source blockchain and distributed ledger project, announced eight new members have joined their consortium including Microsoft, Salesforce and the Ethereum Foundation. ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
The Hyplerledger project is a multi-stakeholder initiative, hosted by the Linux Foundation, which focuses on building blockchain frameworks and tools for enterprises. ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
The existing frameworks include capabilities for smart contract machine development (Hyperledger Burrow), decentralized identity (Hyperledger Indy) and permissioned/permission-less support for Ethereum Virtual Machines (EVM) (Hyperledger Sawtooth). ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
From a tooling perspective, Hyperledger supports the infrastructure for peer-to-peer interactions (Hyperledger Aries), performance benchmarking (Hyperledger Caliper) and shared cryptographic libraries (Hyperledger Ursa). ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
Microsoft’s involvement in blockchain goes back several years as they have been building out capabilities in Azure for organizations requiring blockchain-as-a-service capabilities. ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
These investments include Project Bletchley, R3/Corda/Quorum protocol support and Microsoft-Truffle partnership, to name a few. ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
In addition, Microsoft has been focused on contributing to open standards and specifications by being a founding member of both the Enterprise Ethereum Alliance (EEA) and the Token Taxonomy Initiative (TTI). ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
With Microsoft’s current involvement in collaborating on open standards, joining the Hyperledger project seemed like a logical next step. ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
We’re excited to join the Hyperledger community and look forward to rolling up our sleeves and being an active contributor to both discussions and project code. ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
We believe that developing standards and open specifications, as well as collaborating on implementations of them, is critical to removing customer blockers and accelerating blockchain as a mainstream technology. ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
Through our work related to the EEA and TTI, we have identified several opportunities for Microsoft to lean in and contribute code in project areas such as tokens, ledger integration, and developer experience. ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
Salesforce is relatively new to the blockchain space having recently introduced their low-code blockchain platform for CRM. ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
Their offering was built on Hyperledger Sawtooth and customized for the Salesforce Lightning platform. ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
Lower the barrier for creating trusted partner networks by enabling companies to easily bring together authenticated, distributed data and CRM processes. ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
The motivation for Salesforce to join the Hyperledger project includes tapping into the broader blockchain community. ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
Blockchain is quickly becoming a foundational technology for organizations to deliver a truly connected customer experience and Hyperledger has created a great blockchain community that we're excited to learn from and be a part of. ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
The Ethereum Foundation is proud to lend our support to the efforts of both the @EntEthAlliance and @Hyperledger through our membership today. ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
For additional information about Hyperledger’s open source frameworks and tools, please visit their GitHub repository. ======Microsoft, Salesforce and the Ethereum Foundation Join Open-Source Hyperledger Blockchain Project
Grid is a framework for integrating distributed ledger technology (DLT) solutions with enterprise business systems for the supply chain industry. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
The project consists of reference architectures, common data models and smart contracts, all based-upon open standards and industry best practices. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
The domain of supply chain management is often brought up when debating the opportunity of blockchain solutions. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
Well documented use cases include Seafood tracking, Food safety, Pharmaceutical safety and authenticity and Asset maintenance. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
Since there is established interest in leveraging distributed ledgers across these industries and verticals, the Hyperledger Grid project focuses-on accelerating the development of these solutions through shared capabilities. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
Grid is an ecosystem of technologies, frameworks, and libraries that work together, letting application developers make the choice as to which components are most appropriate for their industry or market model. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
Since many enterprise business systems and markets are relatively mature, Grid seeks to integrate with these solutions with other emerging technologies like blockchains, smart contracts and identity providers. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
A key component in bridging traditional enterprise systems with other emerging technologies is Sabre. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
The initial linkage between Grid and other elements in the stack will be via Sabre, a WebAssembly (WASM) Smart Contract engine. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
By adopting this approach, Grid asserts the strategic importance of WASM and provides a clear interface for integration with platforms inside and outside of Hyperledger. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
The initial implementation of Grid is focused on providing reference implementations of supply chain specific data types, data model and common business logic represented as smart contracts. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
The Grid project will then demonstrate how to combine components from the Hyperledger stack into a single business solution. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
Some of the scenarios that Grid will be focusing on in the future include Asset transformation, Asset exchange and Asset tracking. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
In a recent press release, Cargill vice president Keith Narr explained why they decided to get involved in the Grid project. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
Hyperledger Grid is another way to help make food and agricultural supply chains more inclusive – creating new markets for farmers and developing economies. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
With our wide set of food and agricultural supply chain data, Cargill is leading the industry to work together and improve traceability, trade, food safety, nutrition, farmer livelihoods and more. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
Hyperledger Grid provides an ecosystem of reusable, open-source digital tools that developers can work with to build products, prototypes and applications that address supply-chain use cases, including traceability, food safety, trade settlement and more. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
For additional information on Hyperledger Grid, the project proposal has been published and their code repository is available on GitHub. ======Introducing Hyperledger Grid, a Framework for Building Distributed Supply Chain Solutions
Recoil is a brand new, experimental JavaScript state management library by Facebook that addresses many of the problems larger applications encounter when using the existing Context API. ======Recoil - a New State Management Library for React
Since React is primarily a UI library, developers often use a state management solution alongside React to simplify data handling. ======Recoil - a New State Management Library for React
Many of the existing state management solutions are based around the Flux architecture that was introduced by React in 2014. ======Recoil - a New State Management Library for React
However, while libraries like Redux and MobX ensure that the application state remains consistent, they come with an overhead that is often hard to justify for many applications. ======Recoil - a New State Management Library for React
To combat that, React introduced a simple alternative called the Context API that allows developers to share data through the component tree without having to pass props down manually at every level. ======Recoil - a New State Management Library for React
Recoil provides a solution to developers who wish to avoid full-blown state management systems, but feel too constrained by the Context API. ======Recoil - a New State Management Library for React
Recoil does that by solving three problems with the Context API, as stated by the official documentation. ======Recoil - a New State Management Library for React
The component state can only be shared by pushing it up to the common ancestor, but this might include a huge tree that then needs to re-render. ======Recoil - a New State Management Library for React
Both of these make it challenging to code-split the top of the tree (where the state has to live) from the leaves of the tree (where the state is used). ======Recoil - a New State Management Library for React
Each Atom includes a unique key and a piece of data it will manage while each Selector represents a piece of derived state that can be based on multiple Atoms. ======Recoil - a New State Management Library for React
An excellent example of how to combine the two is the popular todo application that includes two Atoms and a single Selector. ======Recoil - a New State Management Library for React
The first includes the raw list items, while the second consists of the filter ('complete', 'incomplete', 'all', etc. ======Recoil - a New State Management Library for React
To display the todo list, we use a Selector that filters out the todo items based on the selected filter. ======Recoil - a New State Management Library for React
For a full todo list tutorial as well as a good getting started guide, head over to the official documentation. ======Recoil - a New State Management Library for React
Do not forget that Recoil is considered an experimental solution and might not be ready for use in a production application. ======Recoil - a New State Management Library for React
Software development is different for blockchain-based applications; blockchain impacts the way we are used to working, said Sanne Visser, a software tester at Dutch Railways. ======Experiments with Blockchain at Dutch Railways
The first proof of concept at Dutch Railways was a supply chain project where we as a group were inexperienced; for the entire team, it was the first time we were dealing with and figuring out blockchain, explained Visser. ======Experiments with Blockchain at Dutch Railways
The main thing that saved them was that they had so much fun along the way, each of them working on it voluntarily, and as such, motivation and spirits were high. ======Experiments with Blockchain at Dutch Railways
The impact of blockchain on testing is significant mostly because the technology impacts the way we are used to working, said Visser. ======Experiments with Blockchain at Dutch Railways
Each of the usual four stages of software development, development, testing, user acceptance and finally production, is different for blockchain-based applications. ======Experiments with Blockchain at Dutch Railways
As an example, she mentioned the testing environment where testers control which version of an application is installed and manipulate this to test specific application attributes. ======Experiments with Blockchain at Dutch Railways
With blockchain technology a tester is faced with either no testing environment, or testing on a blockchain "testnet", that is not in their control, said Visser. ======Experiments with Blockchain at Dutch Railways
And even testnets are dissimilar enough to a blockchain in production in a lot of aspects (such as international distribution of nodes) so that testing some quality attributes, such as performance, is difficult or even (for now) impossible, she argued. ======Experiments with Blockchain at Dutch Railways
Wherever possible, allow space for investigating whether blockchain technology can add value to an IT-solution, she said. ======Experiments with Blockchain at Dutch Railways
When there is a chance that an immutable, shared ledger offers an added benefit, build an MVP to see if it works for your business, was her advice. ======Experiments with Blockchain at Dutch Railways
Visser suggested looking at the ecosystem in which you operate, your business partners, competitors, and customers. ======Experiments with Blockchain at Dutch Railways
InfoQ is covering European Women in Tech with Q&As and summaries, and interviewed Sanne Visser about her experiences with blockchain. ======Experiments with Blockchain at Dutch Railways
InfoQ: You mentioned in your talk that people find it hard to understand blockchain technology, or only get parts of it. ======Experiments with Blockchain at Dutch Railways
Very few people can explain how their cell phone works, but basic concepts are familiar, such as processors or wireless signals. ======Experiments with Blockchain at Dutch Railways
In the same way people understand blockchain technology in bits and pieces, my audience will understand peer-to-peer sharing for instance, but be unfamiliar with merkle trees. ======Experiments with Blockchain at Dutch Railways
What makes blockchain particularly hard to understand is needing to conceive of software acting as a third party. ======Experiments with Blockchain at Dutch Railways
For example, we understand that banks facilitate payments between us and businesses we buy from; to understand blockchain you need to make the leap that it's not an entity like a bank that facilitates a payment, but software, and this software is called blockchain. ======Experiments with Blockchain at Dutch Railways
InfoQ: What did you do to introduce and spread knowledge about blockchain in your company, and how did that work out. ======Experiments with Blockchain at Dutch Railways
What I wanted to achieve was to start experimenting with the technology within the company, so I was looking for blockchain project opportunities. ======Experiments with Blockchain at Dutch Railways
I tried many different ways to reach my goal; I had a booth at an internal IT market, I published on our intranet, and so forth. ======Experiments with Blockchain at Dutch Railways
In the end what worked best was specifically reaching out to business managers at senior levels, arranging an introduction and then sitting down with them for a cup of coffee. ======Experiments with Blockchain at Dutch Railways
Presentations work well for spreading awareness, but they did not lead to any blockchain projects; the coffee meetings did. ======Experiments with Blockchain at Dutch Railways
Visser: We made so many mistakes, and without expert help we weren't able to correct or even confirm that we had made mistakes. ======Experiments with Blockchain at Dutch Railways
The main lesson from the first PoC, is that we would have liked to have expert help to steer us away from the worst errors. ======Experiments with Blockchain at Dutch Railways
Just to give an example: we had entire photographs uploading to the blockchain, and I now know you shouldn't store huge amounts of data like that on a blockchain. ======Experiments with Blockchain at Dutch Railways
The alternative to reaching out for expert help would be to turn to the blockchain development community; unfortunately, this was not an option for us as we had to keep all project details in-company. ======Experiments with Blockchain at Dutch Railways
Visser: I think software testers, sooner or later, will be asked to test IT-solutions that incorporate blockchain technology, and that the number of blockchain testing projects will grow. ======Experiments with Blockchain at Dutch Railways
I want to develop a testing framework for dealing with blockchain-based applications, that combines all the best efforts already out there and hopefully add to them. ======Experiments with Blockchain at Dutch Railways
Also, I want to form a blockchain testing group to share this knowledge to benefit the entire testing community. ======Experiments with Blockchain at Dutch Railways
I recently received the EuroSTAR Rising Star award; 32 supporters have committed to support me with a half-day of their time. ======Experiments with Blockchain at Dutch Railways
In the next year, I will use that support to help me develop a workshop with a demo-blockchain environment, allowing me to teach testers about the technology, and to let them experiment with ways it might be tested. ======Experiments with Blockchain at Dutch Railways
Autonomous data analytics will be the driver of business analytics in the future and will be seamlessly integrated into our lives. ======Autonomous Analytics: Driving the Future of Data in Business Analytics
John Thuma, from Arcadia Data, spoke at Enterprise Data World 2019 Conference in Boston about self-driving analytics. ======Autonomous Analytics: Driving the Future of Data in Business Analytics
He started off the presentation by asking the question if analytics initiatives are at an ROI cross-roads. ======Autonomous Analytics: Driving the Future of Data in Business Analytics
According to a Gartner report on Business Intelligence project failures, 70-80% of the enterprise BI initiatives are bound for failure. ======Autonomous Analytics: Driving the Future of Data in Business Analytics
The reasons for this are complex technology stacks, communication issues, lack of self service and relying on the past. ======Autonomous Analytics: Driving the Future of Data in Business Analytics
Descriptive analytics are great but they only tell us what's happening and trends, but they don't tell us why or what to do next. ======Autonomous Analytics: Driving the Future of Data in Business Analytics
Also, the friction between the teams in Business, Data Science, and IT areas (Data Science Iron Triangle) doesn't help much with success in analytics initiatives. ======Autonomous Analytics: Driving the Future of Data in Business Analytics
Autonomous analytics will help with the data/information finding its customer, not the other way around. ======Autonomous Analytics: Driving the Future of Data in Business Analytics
Augmented analytics are the next generation analytics capabilities that can automatically prepare and cleanse data, perform feature engineering, find key insights and hidden patterns. ======Autonomous Analytics: Driving the Future of Data in Business Analytics
Automation expedites investigation across millions of variable combinations that would be too time-consuming for a human to do manually. ======Autonomous Analytics: Driving the Future of Data in Business Analytics
Other initiatives like smart cities can also be benefitted by autonomous analytics, with alerts being sent to emergency support services and law enforcement organizations. ======Autonomous Analytics: Driving the Future of Data in Business Analytics
Analytics can also help in redirecting the traffic configuration and alerting the connected vehicles with any critical traffic situations. ======Autonomous Analytics: Driving the Future of Data in Business Analytics
Legacy analytics are complex & expensive in the areas of ETL/data movement and are resulting in higher TCO and time to market. ======Autonomous Analytics: Driving the Future of Data in Business Analytics
Some of the constraints to realize autonomous analytics are scale (can your BI and analytics keep up with growing data volumes. ======Autonomous Analytics: Driving the Future of Data in Business Analytics
Search based BI techniques enables the customers to have a conversation with their data where the users can build their own search engines without moving the data, using Natural Language Processing (NLP) techniques. ======Autonomous Analytics: Driving the Future of Data in Business Analytics
An ideal analytics solution should require zero data movement, should work on-premises & in the cloud, be able to search across the organizations' data lakes and should be easy to setup and customize. ======Autonomous Analytics: Driving the Future of Data in Business Analytics
Thuma concluded the discussion by suggesting data analytics professionals focus on the "Design of Things", not just the "Internet of Things". ======Autonomous Analytics: Driving the Future of Data in Business Analytics
Anna Zawilska, lead user researcher at Babylon Health, recently presented at Webexpo 2019 in Prague the lessons learnt from the experience of delivering remote healthcare through a combination of technology and Artificial Intelligence (AI). ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
Zawilska started her talk mentioning a study from the World Healthcare Organization, according to which at least 50% of the world’s population cannot obtain essential health services. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
In that context, combining the ubiquity of mobile devices with the diagnosis power of Artificial Intelligence has the potential to broaden the access of healthcare services. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
Babylon’s engineers, doctors, and scientists developed an AI system that can receive data about the symptoms someone is suffering from, compare the information to a database of known conditions and illnesses to find possible matches, and then identify a course of action and related risk factors. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
In the Babylon mobile application, a typical user flow would start with the application asking the user (patient) to describe the symptoms he or she is experiencing. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
In a second stage, depending on the declared symptoms, further questions would be asked to further refine the set of possible conditions affecting the patient. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
The first assumption the Babylon team made was that patients would trust their Chatbot (where patients enter their symptoms) as much as they trust doctors. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
However, key observations coming from actual experience showed crucial differences in user behaviour with a human doctor vs a machine-based technology. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
Furthermore, while a patient would rarely get up and leave a consultation with a human doctor before it’s over, Chatbot users were much more likely to end the consultation early. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
Lastly, while patients usually believe that the advice given by the doctor should be followed, Chatbot users had a lower propensity to trust advice from the Chatbot and follow the given prescriptions. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
Babylon Health concluded that user trust cannot be assumed, and as a consequence, they needed to design for increasing trust. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
Zawilska provides an example of a change made to the user interface: when a hypothetical user would be asked, “Do you have any problem moving your neck. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
In this case, for instance, the application would display a message along the lines of, “I’m asking this because I’m trying to rule out a tension headache. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
For people of your profile, neck issues along with a headache are a strong predictor of tension headaches. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
Zawilska quoted recent controversies (involving Theranos, or DNA sequencing) which contributed to eroding the trust in the latest innovations in health-care technology. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
The second assumption that was made was that clinical safety was the only criteria by which to evaluate the success of Babylon’s predictive AI. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
AI is typically trained with large amount of data, with the resulting AI model being tested against a test set using some evaluating criteria. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
Zawilska explained that using clinical safety as a sole criteria for validating the AI model presented a higher risk to adversely effect the user experience. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
As a matter of fact, optimizing for critical safety may mean that the AI would recommend in some cases that a patient visit the emergency room (ER), while the patient's condition need not necessarily require them to do so. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
A large proportion of these occurrences may result in the patient attributing a lower value to the application. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
Zawilska mentions that the application could theoretically, independently of the user condition, display a comforting message and recommend that the user take pain killers. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
Zawilska explained that the sweet spot consisted in sending patients to the ER when needed, and reassuring and prescribing when appropriate. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
The third assumption mentioned by Zawilska, and which impacted product development, was to “move fast and break things”. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
The motto, popularized by Facebook’s Mark Zuckerberg, emphasizes the need for speed in delivery of technology. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
In recent years, criticism has emerged, with a recommendation to replace “minimum viable products” with “minimum virtuous products”, in which new offerings test their effects on stakeholders and build in guards against potential harms. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
Zawilska gave examples of scenarios in which user interface changes may potentially result in user behaviours with adversarial effects on clinical safety. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
In those cases, the company would first study and calibrate those effects before deciding to move forward with the proposed changes. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
Babylon is a UK start-up with a self-declared mission to “put an accessible and affordable health service in the hands of every person on earth”. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
Babylon seeks to achieve this goal by leveraging artificial intelligence (AI) tools combined with human medical expertise. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
Webexpo is a conference for developers, UX professionals, designers, and marketers to meet up and share their experience. ======WebExpo 2019: Make Healthcare Affordable and Accessible Using Tech and AI
Ockam is a serverless platform that aims to make it easier for IoT developers to add blockchain-based identity, trust, and interoperability in their IoT devices. ======Ockam Brings Blockchain Serverless Identification to IoT Devices
By embedding the Ockam SDK into their devices, developers can make them part of the Ockam blockchain network, a decentralized, open platform that enables secure cryptographic identity management based on a recent W3C standard called Decentralized Identifiers (DID). ======Ockam Brings Blockchain Serverless Identification to IoT Devices
Decentralized Identifiers (DIDs) are a new type of identifier for verifiable, "self-sovereign" digital identity. ======Ockam Brings Blockchain Serverless Identification to IoT Devices
DIDs are fully under the control of the DID subject, independent from any centralized registry, identity provider, or certificate authority. ======Ockam Brings Blockchain Serverless Identification to IoT Devices
The idea of self-sovereign identity has its roots in the 1970's but it is thanks to blockchain that it is becoming a reality. ======Ockam Brings Blockchain Serverless Identification to IoT Devices
Matthew Gregory: One of the core benefits of Ockam is how the SDK abstracts away complex infrastructure. ======Ockam Brings Blockchain Serverless Identification to IoT Devices
Rather than standing up complex cryptography infrastructure by hand, the developers building on top of Ockam incorporate simple function calls in their code base to get the benefits of Public Key Infrastructure without needing special expertise. ======Ockam Brings Blockchain Serverless Identification to IoT Devices
Just like Heroku's "git push master" unlocked the magic of the cloud, Ockam helps developers unlock innovation in IoT. ======Ockam Brings Blockchain Serverless Identification to IoT Devices
Gregory: Every developer gets to the point in a project where they must choose how to add identity, trust and interoperability into their IoT devices. ======Ockam Brings Blockchain Serverless Identification to IoT Devices
Do nothing: this is exceptionally common and leads to botnets and massive security vulnerabilities in devices. ======Ockam Brings Blockchain Serverless Identification to IoT Devices
Build their own end-to-end IoT infrastructure: this is a massive undertaking and costs million of dollars and requires specific expertise. ======Ockam Brings Blockchain Serverless Identification to IoT Devices
Buy an IoT platform vendor solution: end-to-end platforms are complex to implement, have high switching costs and lead to vendor lock-in which limits interoperability. ======Ockam Brings Blockchain Serverless Identification to IoT Devices
Today, with the Ockam SDK, developers now have a better option: write a couple lines of code to give their device a secure immutable identity that is interoperable with the rest of their technology stack. ======Ockam Brings Blockchain Serverless Identification to IoT Devices
Gregory: Blockchain is not what Ockam is; rather, blockchain is just one component in how Ockam works. ======Ockam Brings Blockchain Serverless Identification to IoT Devices
As part of the Ockam blockchain network protocol, we utilize the DID standard for identities, and every exchange of data must be signed with the secret key of the device that sent that data. ======Ockam Brings Blockchain Serverless Identification to IoT Devices
The privacy of user data can be handled with many of the widely used best practices of data encryption, and access permissions. ======Ockam Brings Blockchain Serverless Identification to IoT Devices
Data centres create more emissions than the aviation industry due to their energy usage and 24x7 availability, and the growth of the cloud computing and the mining of cryptocurrencies is increasing the impact technology is having on our climate. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Moving existing servers to providers who use renewable sources of electricity could lead to planet-wide climate improvements. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Jason Box, climatologist & professor of glaciology at The Geologic Survey of Denmark and Greenland (GEUS), and Paul Johnston, CEO at roundaboutlabs, will talk about the risk of climate change and what tech can do at QCon London 2019. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Many tech people are unaware of the huge impact that technology has on the Greenhouse Gas Emissions globally, and even those who are aware feel hugely disempowered in the area of climate change. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Google offset 100% of their cloud usage with renewable energy, Microsoft purchases carbon credits to offset 100% of their cloud usage, and AWS have four public regions that are powered by 100% renewable energy. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Users of these cloud computing vendors can now begin to make an informed choice with regards to environmental impact. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Box and Johnston argue that people who are currently working with vendors that do not offer such programs should start to ask for their data centres and cloud infrastructure to be powered by renewable energy. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
This should significantly increase requirements for renewable energy, which in turn should increase the demand across the network. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Customers should also ask for increased transparency on environmental impact, and request public disclosure of associated data, such as the carbon footprint as a line item on each account. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
For example, the QCon team wants to offset carbon from flights into the host city of the conference, and is matching funds with attendees who offset their carbon footprint by contributing to the Greenland Reforestation program. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
As part of QCon London, taking place in the Queen Elizabeth II Conference Centre, March 4-8th, InfoQ spoke with Jason Box and Paul Johnston about what is causing climate change and what tech can do to reduce it. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Jason Box: Mainly fossil fuel combustion and secondarily deforestation and biomass burning have elevated atmospheric CO2 by 50% since year 1850. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Earth orbital changes had the climate cooling over the last 2000 years until ~1850 when a sharp warming began and forestalled the next Ice Age, by a large margin. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Paul Johnston: It’s pretty clear to me from the evidence I’ve seen that it’s humanity that is causing these changes in our climate, and it’s largely through the burning of fossil fuels. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
For that, we need broad agreement and political will across the major countries of the world to implement the Paris Agreement, although even that is probably only the minimum that we need to do. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
A better answer is probably to make your voices heard in the right forums and vote for parties in elections that best describe these values. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
However, not without removing several hundred Gtons of carbon from the atmosphere will we have a stable climate. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
How to drawdown atmospheric carbon will require a portfolio response, that is, no single solution can do it. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
I think other stabilization wedges will come from biotechnology, meaning, plant-based CO2 sequestration. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Most are also unaware of the huge impact that technology has on the Greenhouse Gas Emissions globally. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Data centres create more emissions than aviation due to their energy usage and their constant 24x7 availability. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Cryptocurrencies and mining of cryptocurrencies have also seen a huge spike in data centre energy usage over the past few years, with Bitcoin mining currently using around the same amount of electricity as Singapore daily (and Bitcoin is definitely not incentivising green energy as many believe). ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
A quick answer is to look at Google who offset 100% of their cloud usage with renewable energy, Microsoft who purchase carbon credits to offset 100% of their cloud usage and AWS who have four public regions that are powered by 100% renewable energy: Ireland, Frankfurt, Montreal and Oregon. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Greenland has a large and unexploited hydropower potential and a government very interested in increasing its economic sovereignty through data centers. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
As attention turns to the overlooked north, as the Arctic opens up, we’ll see the Arctic more on the geopolitical agenda. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Johnston: If customers start to ask for their data centres and cloud to be powered by renewable energy then it should significantly increase the data centres requirements for renewable energy, which should in turn increase the demand across the network. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
As the data centre market is a growing market within the energy sector, this means that it should increase investment in renewable technologies, and that would only improve the chances of better technologies reaching the wider market more quickly. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
My hope is that it will also bring the very wealthy tech companies who run the major cloud services into the equation in terms of innovation and resources as well. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
InfoQ: How can companies know for sure that providers will use renewable sources of energy for the servers where their applications are running. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Unfortunately, the data is relatively difficult to understand as well, although giving percentages is helpful, and 100% is a useful number, although most ordinary people don’t understand what "100% offset" really means. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
This would be significantly improved though, if the providers gave the carbon footprint as a line item on each account, because it would allow customers to both see the impact of their technology and give them a way of mitigating their impact. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Google and Microsoft, would be able to state that their cloud services are 100% offset and so an account carbon footprint could be zero, although even that is contentious as it depends on how an offset is used as to whether it truly offsets the carbon that is used. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
In partnership with QCon, we’ve established a carbon drawdown/ carbon offset service, a charity with dual EU charity and 501c3 US tax status. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
I’m very familiar with the logistics to get seedlings from Icelandic nurseries to Greenland at a cost of 3. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
InfoQ asked Roxanne Beverstein, co-founder of and VP of sales for C4Media, about the collaboration between QCon and Greenland Trees. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Roxanne Beverstein: We think that it’s our responsibility as a business to consider our impact on the environment; this is why we’ve started the Carbon Offset program for our QCon events. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
We know that the single largest component to our carbon footprint is from those who fly in to attend the conference. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
Therefore, we’ve chosen to focus on offsetting carbon from aviation and will be contributing to Jason’s Greenland Reforestation program called Greenlandtrees. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
QCon will be contributing up to $5K USD in matching funds to those attendees who offset their carbon footprint by contributing to Jason’s Greenland Reforestation program. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
This is a crowdfunded program with a goal of $40K USD, which will allow Jason and his team to plant 10K trees or offset the carbon created by 1,000+ round trip flights from San Francisco to London. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
As per Jason, "This program will help bring down the atmospheric carbon and put a dent in climate change. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
There is information on this program on the QCon London site with a link to the reforestation project in the "unofficial event" section of the site. ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
We are hosting a breakfast with Jason on Wednesday, March 6, from 7:15-8:20am at QCon London (Windsor room on the 5th Floor), which we’re calling "Breakfast with a Climatologist". ======The Risk of Climate Change and What Tech Can Do: QCon London Q&A
The latest version of open-source distributed pub-sub messaging framework Apache Pulsar enables companies to move "beyond batch" by acting on data in motion. ======Distributed Messaging Framework Apache Pulsar 2.0 Supports Schema Registry and Topic Compaction
Pulsar Functions: This stream-native processing capability was first announced as a preview feature earlier this year. ======Distributed Messaging Framework Apache Pulsar 2.0 Supports Schema Registry and Topic Compaction
Pulsar Functions are lightweight compute processes that can be used to apply transformations and analytics directly to data as it flows through Pulsar, without requiring external systems or add-ons. ======Distributed Messaging Framework Apache Pulsar 2.0 Supports Schema Registry and Topic Compaction
Schema Registry: The Schema Registry simplifies development of data-driven applications by providing developers the ability to define and validate the structure and integrity of data flowing through Pulsar. ======Distributed Messaging Framework Apache Pulsar 2.0 Supports Schema Registry and Topic Compaction
Topic Compaction: This is a new enhancement to Pulsar in coordination with the Apache Bookkeeper solution for streaming data storage that improves performance. ======Distributed Messaging Framework Apache Pulsar 2.0 Supports Schema Registry and Topic Compaction
Topic compaction is a process that runs in the Pulsar broker to build a snapshot of the latest value for each key in a topic. ======Distributed Messaging Framework Apache Pulsar 2.0 Supports Schema Registry and Topic Compaction
The topic compaction process reads through the backlog of the topic, retaining only the latest message for each key in a compacted backlog. ======Distributed Messaging Framework Apache Pulsar 2.0 Supports Schema Registry and Topic Compaction
InfoQ spoke with Matteo Merli, the co-founder of Streamlio and the architect and lead developer of Pulsar while at Yahoo, about Pulsar framework and its product roadmap. ======Distributed Messaging Framework Apache Pulsar 2.0 Supports Schema Registry and Topic Compaction
Matteo Merli: Like a number of other frameworks, Pulsar provides distributed messaging capabilities accessible by a variety of clients. ======Distributed Messaging Framework Apache Pulsar 2.0 Supports Schema Registry and Topic Compaction
Pulsar differentiates itself with capabilities that make it possible to keep up with the requirements of modern data-driven applications and analytics without the cost and complexity of alternatives. ======Distributed Messaging Framework Apache Pulsar 2.0 Supports Schema Registry and Topic Compaction
More specifically, those capabilities include better throughput and latency, scalability, stream-native function processing, and support for both publish-subscribe messaging and message queuing, multi-datacenter replication, security and resource management. ======Distributed Messaging Framework Apache Pulsar 2.0 Supports Schema Registry and Topic Compaction
Merli: As an open source project, the roadmap for Apache Pulsar is shaped by the Pulsar community of contributors and users. ======Distributed Messaging Framework Apache Pulsar 2.0 Supports Schema Registry and Topic Compaction
Current development work that is expected to release soon includes support for additional access interfaces, an expanded set of connectors to data sources and repositories, enhancements to provide multi-tier storage capabilities, an expanded set of supported schema formats. ======Distributed Messaging Framework Apache Pulsar 2.0 Supports Schema Registry and Topic Compaction
1 version last week which includes fixes to Python packages on PyPI and REST APIs provided by Pulsar proxy. ======Distributed Messaging Framework Apache Pulsar 2.0 Supports Schema Registry and Topic Compaction
Kevin Hoffman, distributed systems engineer at Capital One, discussed at the WebAssembly summit the current state of the art in WebAssembly and what can be built with it today. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
Hoffman peeked at a containerless future where WebAssembly modules are the de-facto unit of immutable deployment in the cloud, at the edge, and in IoT and embedded devices. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
Hoffman started with mentioning speed, small footprint, security model, developer productivity, and rapid, continuous deployment as key benefits of Web Assembly in the browser. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
WebAssembly is portable: the same file can run anywhere there is a host, which can be the browser, the cloud, an embedded device, and more. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
So we need to make sure [that] as we go forward we don’t do anything that gets in the way of WebAssembly portability benefits. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
The module can be written in almost any language, such as Rust, Go, Zig, AssemblyScript, C, C++, and more. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
Caveats, however, apply to Go, as the current syscall/js implementation assumes the existence of a JavaScript runtime. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
Hoffman continued with listing ways to run WebAssembly outside the browsers and divided the landscape into low-level, mid-level, and high-level runtimes. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
waPC (for WebAssembly procedure calls) features bi-directional functional calling, arbitrary binary payloads. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
waPC thus allows passing information back and forth between the host runtime and WebAssembly and working around the WebAssembly limitation of supporting only numerical arguments. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
Additionally, the argument passing is managed in a way that is memory agnostic: neither side is aware of the other side’s memory allocation patterns. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
Interface types (Wasm proposal for interoperability), Emscripten (C/C++) and wasmbindgen (Rust) work by allowing the host to allocate memory inside the guest or vice versa, which means that the interaction is stateful. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
If the host requests memory allocation for data and then crashes, a recovery mechanism must be built that reconstitutes the Wasm instance with the exact same state it had prior to the crash. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
Hoffman warned that allocating or freeing memory explicitly across the guest/host boundary is not only cloud-antagonistic but a huge source of potential bugs and memory leaks. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
We want developers to build web services or microservices and functions as pure business logic compiled into a WebAssembly module that is secured and signed and then dynamically bound to capabilities. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
[That] takes away all the boilerplate that we spend on non-functional requirements such as the message broker, HTTP, key-value stores. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
At the moment, the host and guest are written in Rust, with a view to having a Go SDK, once Go becomes more compliant with the WebAssembly specifications. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
Hoffman used Isaac Newton’s quote relating to the progress achieved by standing on the shoulders of giants to concede that the WebAssembly community may have to build its own shoulders. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
More tooling is necessary and the community needs to work on education, documentation, developer experience, and more. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
Hoffman concluded with a demonstration of tools in each runtime level, which he billed as the most important part of the presentation. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
The first demo (low-level runtime) features a simple function adding two 32-bit integers (i32) with a source code using the WebAssembly text format, based on S-expressions. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
In the last demo of the talk, Hoffman illustrated options enabled by using WebAssembly in the cloud which are not available with containers. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
Hoffman shows a WebAssembly module running as a service in the cloud being live-swapped with another version without having to provision new resources or dropping requests (zero-downtime deployment). ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
Hoffman proceeded to show how the key-value stored used in the service can also be removed from the host runtime without resulting in a catastrophic service failure. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
[referring to the key-value store removal] The host is up enough to be able to give me a decent error message so the cluster knows that I failed the health-check or if I have downstream circuit breakers those can all trigger with the appropriate response rather than having a catastrophic failure […]. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
[referring to the key-value store swap] Without taking the host down, I can perform a live update of my business logic, and I can perform a live-swap of any capability provider. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
The complete talk, including additional technical details and the complete demos, is available on the WebAssembly Summit Youtube channel. ======Building a Containerless Future with WebAssembly - Kevin Hoffman at WebAssembly Summit
eBay's Accelerator data processing framework provides parallel execution and automatic organization of source code, input data, and results. ======eBay's Accelerator Data Processing Framework Provides Parallel Execution and Live Recommendations
It can be used for data analysis, algorithm development as well as a live recommendation system with large data files and several CPUs. ======eBay's Accelerator Data Processing Framework Provides Parallel Execution and Live Recommendations
It can also help with the administration and bookkeeping of data files, computations, results, and how they are related. ======eBay's Accelerator Data Processing Framework Provides Parallel Execution and Live Recommendations
The framework is intended to work on log files such as transaction logs, event logs, and database dumps. ======eBay's Accelerator Data Processing Framework Provides Parallel Execution and Live Recommendations
Accelerator is a client-server based application -- its architecture includes a runner client and two servers called daemon and urd. ======eBay's Accelerator Data Processing Framework Provides Parallel Execution and Live Recommendations
In parallel, all jobs will be stored by the urd server together with their dependencies in a log-file based database. ======eBay's Accelerator Data Processing Framework Provides Parallel Execution and Live Recommendations
The dataset is the Accelerator’s default storage type and is designed for parallel processing and high performance. ======eBay's Accelerator Data Processing Framework Provides Parallel Execution and Live Recommendations
Datasets are built on top of jobs, so datasets are created by methods and stored in job directories, just like any job result. ======eBay's Accelerator Data Processing Framework Provides Parallel Execution and Live Recommendations
A single job may contain any number of datasets, so it's possible to split an input dataset into several new datasets. ======eBay's Accelerator Data Processing Framework Provides Parallel Execution and Live Recommendations
Data streaming helps with processing continuous chunks of data which is much more efficient than performing a query in a database. ======eBay's Accelerator Data Processing Framework Provides Parallel Execution and Live Recommendations
Streaming is the optimum way to achieve high bandwidth from disk to CPU and makes good use of the operating system’s RAM-based disk buffers. ======eBay's Accelerator Data Processing Framework Provides Parallel Execution and Live Recommendations
Before being open sourced, it has been in use in projects for companies like Safeway, Starbucks, eBay, and Vodafone. ======eBay's Accelerator Data Processing Framework Provides Parallel Execution and Live Recommendations
If you are interested in learning more about ExpertMaker Accelerator, checkout its Github repository, installer repository, and the user reference manual. ======eBay's Accelerator Data Processing Framework Provides Parallel Execution and Live Recommendations
In a recent blog post, the Hyperledger project announced their 13th project called Hyperledger Aries, which provides an interoperable identity management toolkit that enables creating, transmitting and storing verifiable digital certificates. ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
Using this toolkit, organizations can support secure, interoperable peer-to-peer messaging across different distributed ledger technologies (DLT). ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
Identity management continues to be one of the most important and challenging aspects of building DLT applications. ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
Since 2017 alone, more than 600 million personal details – such as addresses or credit card numbers – have been hacked, leaked or breached from organizations. ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
Hyperledger Aries plans to address some of these identity challenges through the use of verifiable digital credentials. ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
Initiatives and solutions focused on creating, transmitting and storing verifiable digital credentials will benefit from a shared, reusable, interoperable tool kit. ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
The toolkit has roots from both the Hyperledger Indy, from a resolver implementation perspective, and Hyperledger Ursa, which it has leveraged some cryptographic functionality from. ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
However, Hyperledger Aries does provide a blockchain interface layer, known as a resolver, that allows for the creation and signing of blockchain transactions. ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
It also includes secure storage that acts as a cryptographic wallet where secrets can be stored and includes an implementation of a Decentralized Key Management System (DKMS) which is currently being incubated in Hyperledger Indy. ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
Aries includes an encrypted messaging system for off-ledger interactions between clients across different transport protocols and the ability to abstract higher level protocols through API-based secure messaging interactions. ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
Additional technology from another Hyperledger project, Hyperledger Ursa, is being leveraged within Aries. ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
An implementation of Zero Knowledge Proof (ZKP) capable W3C verifiable credentials using the ZKP primitives is being included. ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
ZKP-capable W3C verifiable credentials can represent the same knowledge that may be found in physical credentials, such as a driver’s license, passport or health insurance card, but includes privacy-preserving and data-minimization features. ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
While the generic Aries resolver interface will support Hyperledger Indy, it is flexible so that developers can build a pluggable method using another decentralized identifier (DID) method resolver based upon Hyperledger Fabric or Ethereum. ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
The ultimate goal of Hyperledger Aries is to provide a dynamic set of capabilities to store and exchange data related to blockchain-based identity. ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
These capabilities will range from the secured, secret storage of data, such as private keys, up to the capability of globally accessible data that can be viewed and accessed by anyone. ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
An example of such support is the creation of a secure storage solution similar to the wallet available in Hyperledger Indy today. ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
Developers can learn more about Hyperledger Aries by visiting their wiki or joining the Hyperledger chat channel. ======Introducing Interoperable Blockchain Identity Solutions with Hyperledger Aries
IBM recently released the IBM Equal Access Toolkit and the Accessibility Checker, two new open-source toolkits that strive to give designers, developers, and testers a set of tools to make websites and applications accessible. ======IBM Launches Equal Access Toolkit to Help Developers Write Accessible Applications
Simeon McAleer, manager in the IBM Accessibility Research team, explained in the release blog post the motivation behind the toolkits. ======IBM Launches Equal Access Toolkit to Help Developers Write Accessible Applications
[…] an industry sample has found that in 2020 over 98 percent of home pages had a detectable accessibility error. ======IBM Launches Equal Access Toolkit to Help Developers Write Accessible Applications
Accessibility can be forgotten or left until too late in the process when it is difficult to retrofit the site or application. ======IBM Launches Equal Access Toolkit to Help Developers Write Accessible Applications
Knowledge, discipline and tools are all essential to building in accessibility throughout a development process. ======IBM Launches Equal Access Toolkit to Help Developers Write Accessible Applications
The IBM Equal Access Toolkit is a holistic set of guidelines that addresses the fact that first-class accessible products result from teamwork with the project stakeholders across the project lifecycle. ======IBM Launches Equal Access Toolkit to Help Developers Write Accessible Applications
The first phase (Plan) seeks to identify project needs and inject accessibility into sprints and releases. ======IBM Launches Equal Access Toolkit to Help Developers Write Accessible Applications
The first phase involves primarily product owners (offering managers in IBM parlance), architects, and team leads. ======IBM Launches Equal Access Toolkit to Help Developers Write Accessible Applications
The second phase (Design) captures the necessity for Interaction, visual, and content designers to address almost all aspects of the Web Content Accessibility Guidelines (WCAG). ======IBM Launches Equal Access Toolkit to Help Developers Write Accessible Applications
The fifth and last phase (Launch) ensures that accessibility reports are available for release managers and QA leads to review and improve on for future releases. ======IBM Launches Equal Access Toolkit to Help Developers Write Accessible Applications
The accessibility checker is a browser extension that automates the evaluation of accessibility issues. ======IBM Launches Equal Access Toolkit to Help Developers Write Accessible Applications
As can be seen in the screenshot, the extension gives warning about accessibility issues and pinpoints the location (for instance the HTML element) or cause of the issue for developers to investigate and remedy. ======IBM Launches Equal Access Toolkit to Help Developers Write Accessible Applications
Databricks, the company behind the Apache Spark data analytics engine, recently announced the Unified Data Analytics Platform, including an automated machine learning tool called AutoML Toolkit. ======Databricks' Unified Analytics Platform Supports AutoML Toolkit
The toolkit can be used to help data science teams be productive by automating various steps of the data science workflow  – including feature engineering, hyperparameter tuning, model search, and deployment – for a fully controlled and transparent augmented ML experience. ======Databricks' Unified Analytics Platform Supports AutoML Toolkit
The Databricks Labs project is an experimental end-to-end supervised learning solution for automating the steps like feature clean-up, feature vectorization, model selection and training, hyper parameter optimization and selection, batch prediction and logging of model results and training runs. ======Databricks' Unified Analytics Platform Supports AutoML Toolkit
Databricks Workspace: With the goal of unifying data science and engineering, the workspace handles all analytic processes (from ETL to model training and deployment), leveraging shared interactive notebooks, tools, and APIs. ======Databricks' Unified Analytics Platform Supports AutoML Toolkit
Databricks Runtime: The runtime component helps with data preparation and continuously trains and deploys the models for AI/ML applications. ======Databricks' Unified Analytics Platform Supports AutoML Toolkit
It supports integrations between Hyperopt, MLlib, and MLflow, which enables distributed conditional hyperparameter tuning, automated tracking, and enhanced visualizations. ======Databricks' Unified Analytics Platform Supports AutoML Toolkit
The users can get started with pre-configured clusters including some of the popular ML frameworks like Hadoop, Kafka, Spark, Parquet, TensorFlow, Keras, and Scikit Learn. ======Databricks' Unified Analytics Platform Supports AutoML Toolkit
Databricks Cloud Service: The cloud service helps with managing the infrastructure complexity by offering a fully managed service on the cloud. ======Databricks' Unified Analytics Platform Supports AutoML Toolkit
Databricks is also offering third-party machine learning integrations with H2O's Sparkling Water, DataRobot and XGBoost. ======Databricks' Unified Analytics Platform Supports AutoML Toolkit
For more information on the new analytics platform and AutoML toolkit, check out the following additional resources. ======Databricks' Unified Analytics Platform Supports AutoML Toolkit
